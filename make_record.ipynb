{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "size = (227, 227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resize images to the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def may_create_directory(path):\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "        logging.info('[create_directory] remove file: %s', path)\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        logging.info('[create_directory] create directory: %s', path)\n",
    "    else:\n",
    "        logging.info('[create_directory] directory already exists: %s', path)\n",
    "\n",
    "def may_resize_images(from_dir, to_dir, size):\n",
    "    logging.info('[resize_images] start')\n",
    "    may_create_directory(to_dir)\n",
    "    count = 0\n",
    "    for image_path in glob.glob(os.path.join(from_dir, '*.jpg')):\n",
    "        image_file_name = os.path.split(image_path)[1]\n",
    "        to_path = os.path.join(to_dir, image_file_name)\n",
    "        if not os.path.isfile(to_path):\n",
    "            image = cv2.imread(image_path)\n",
    "            resized_image = cv2.resize(image, size)  # interpolation=cv2.INTER_LINEAR\n",
    "            #resized_image = cv2.resize(image, size, interpolation=cv2.INTER_CUBIC))\n",
    "            cv2.imwrite(to_path, resized_image)\n",
    "            count += 1\n",
    "        if count != 0 and count % 1000 == 0:\n",
    "            logging.info('[resize_images] finish: count = %d', count)\n",
    "    logging.info('[resize_images] finished: total_written_files = %d', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize training images\n",
    "from_train_dir = os.path.join(data_dir, 'train')\n",
    "to_train_dir = os.path.join(data_dir, 'resized_train')\n",
    "may_resize_images(from_train_dir, to_train_dir, size)\n",
    "\n",
    "# resize test images\n",
    "from_test_dir = os.path.join(data_dir, 'test1')\n",
    "to_test_dir = os.path.join(data_dir, 'resized_test1')\n",
    "may_resize_images(from_test_dir, to_test_dir, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_and_labels(dir, train_ratio):\n",
    "    if not (0.0 <= train_ratio and train_ratio <= 1.0):\n",
    "        raise ValueError('train_ratio must between 0.0 and 1.0')\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_path in glob.glob(os.path.join(dir, '*.jpg')):\n",
    "        images.append(image_path)\n",
    "        image_file_name = os.path.split(image_path)[1]\n",
    "        if image_file_name.startswith('cat'):\n",
    "            labels.append(0)    # cat is 0\n",
    "        elif image_file_name.startswith('dog'):\n",
    "            labels.append(1)    # dog is 1\n",
    "        else:\n",
    "            raise ValueError(\"image name must be starts with 'cat' or 'dog': {}\".format(image_file_name))\n",
    "    assert(len(images) == len(labels))\n",
    "    # shuffle samples\n",
    "    samples = np.array([images, labels])\n",
    "    samples = samples.transpose()\n",
    "    np.random.shuffle(samples)\n",
    "    # split dataset into train-part and val-part\n",
    "    num = len(images)\n",
    "    train_num = int(num * train_ratio)\n",
    "    train_images = list(samples[:train_num, 0])\n",
    "    train_labels = list(samples[:train_num, 1].astype(np.uint8))\n",
    "    val_images = list(samples[train_num:, 0])\n",
    "    val_labels = list(samples[train_num:, 1].astype(np.uint8))\n",
    "    return (train_images, train_labels, val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dir = to_train_dir\n",
    "train_ratio = 0.96\n",
    "train_images, train_labels, val_images, val_labels = get_images_and_labels(train_val_dir, train_ratio)\n",
    "logging.info('len(train_images) = %d', len(train_images))\n",
    "logging.info('len(train_labels) = %d', len(train_labels))\n",
    "logging.info('len(val_images) = %d', len(val_images))\n",
    "logging.info('len(val_labels) = %d', len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train and val record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(images, labels, save_dir, file_name):\n",
    "    path = os.path.join(save_dir, file_name)\n",
    "    assert(len(images) == len(labels))\n",
    "    num = len(images)\n",
    "    writer = tf.python_io.TFRecordWriter(path)\n",
    "    logging.info('[create_record] start: write to %s', path)\n",
    "    for i in np.arange(num):\n",
    "        image = cv2.imread(images[i]) # differ from open(images[i], 'rb').read()\n",
    "        image_raw = image.tostring()\n",
    "        #with open(train_images[i], 'rb') as fid:\n",
    "        #    image_raw = fid.read()\n",
    "        label = int(labels[i])\n",
    "        # ohe-hot code\n",
    "        #onehot_code = [[1, 0], [0, 1]]\n",
    "        #label = onehot_code[label] \n",
    "        example = tf.train.Example(features = tf.train.Features(\n",
    "            feature = {\n",
    "                'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw])),\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "            }\n",
    "        ))\n",
    "        writer.write(example.SerializeToString())\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            logging.info('[create_record] finish: count = %d', i + 1)\n",
    "    writer.close()\n",
    "    logging.info('[create_record] finished: total_examples = %d', i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_record(train_images, train_labels, data_dir, 'train.record')\n",
    "create_record(val_images, val_labels, data_dir, 'val.record')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
